project_name: 'hpp_dqn'
episodes: 2000
agent:
  batch_size: 512
  gamma: 0.95
  eps_start: 0.5
  eps_end: 0.01
  eps_decay: 10000
  target_update: 200
  n_actions: 8
  n_layers: 1
  capacity: 100000
  learning_rate: 0.0001

environment:
  map_name: Berlin_0_256
  task: 50
  window_size: 21
  goal_reward: 1
  distance_reward_weight: 0.05
  collision_reward: -2
  move_reward: -0.01
  max_steps: 100
  path: ../../dataset/256/

